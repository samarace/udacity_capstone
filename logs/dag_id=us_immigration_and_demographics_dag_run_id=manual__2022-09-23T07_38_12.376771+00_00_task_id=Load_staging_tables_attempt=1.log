1.0.0.127.in-addr.arpa
*** Reading local file: /Users/samar/airflow/logs/dag_id=us_immigration_and_demographics_dag/run_id=manual__2022-09-23T07:38:12.376771+00:00/task_id=Load_staging_tables/attempt=1.log
[2022-09-23 13:08:17,824] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: us_immigration_and_demographics_dag.Load_staging_tables manual__2022-09-23T07:38:12.376771+00:00 [queued]>
[2022-09-23 13:08:17,830] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: us_immigration_and_demographics_dag.Load_staging_tables manual__2022-09-23T07:38:12.376771+00:00 [queued]>
[2022-09-23 13:08:17,830] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-09-23 13:08:17,830] {taskinstance.py:1377} INFO - Starting attempt 1 of 2
[2022-09-23 13:08:17,830] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-09-23 13:08:17,840] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): Load_staging_tables> on 2022-09-23 07:38:12.376771+00:00
[2022-09-23 13:08:17,843] {standard_task_runner.py:52} INFO - Started process 23536 to run task
[2022-09-23 13:08:17,848] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'us_immigration_and_demographics_dag', 'Load_staging_tables', 'manual__2022-09-23T07:38:12.376771+00:00', '--job-id', '412', '--raw', '--subdir', 'DAGS_FOLDER/us_immigration_and_demographics_dag.py', '--cfg-path', '/var/folders/nw/yq4dq6kn2vq9jtj6_s7xh45h0000gn/T/tmpmvg_rg6w', '--error-file', '/var/folders/nw/yq4dq6kn2vq9jtj6_s7xh45h0000gn/T/tmpsgvk7h4g']
[2022-09-23 13:08:17,851] {standard_task_runner.py:80} INFO - Job 412: Subtask Load_staging_tables
[2022-09-23 13:08:17,903] {task_command.py:371} INFO - Running <TaskInstance: us_immigration_and_demographics_dag.Load_staging_tables manual__2022-09-23T07:38:12.376771+00:00 [running]> on host 1.0.0.127.in-addr.arpa
[2022-09-23 13:08:17,952] {taskinstance.py:1589} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Samar Javed
AIRFLOW_CTX_DAG_ID=us_immigration_and_demographics_dag
AIRFLOW_CTX_TASK_ID=Load_staging_tables
AIRFLOW_CTX_EXECUTION_DATE=2022-09-23T07:38:12.376771+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-09-23T07:38:12.376771+00:00
[2022-09-23 13:08:17,954] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/nw/yq4dq6kn2vq9jtj6_s7xh45h0000gn/T
[2022-09-23 13:08:17,954] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'python /Users/samar/airflow/us_immigration_and_demographics_staging.py']
[2022-09-23 13:08:17,961] {subprocess.py:85} INFO - Output:
[2022-09-23 13:08:20,061] {subprocess.py:92} INFO - 22/09/23 13:08:20 WARN Utils: Your hostname, Samars-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.29.187 instead (on interface en0)
[2022-09-23 13:08:20,063] {subprocess.py:92} INFO - 22/09/23 13:08:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2022-09-23 13:08:20,417] {subprocess.py:92} INFO - 22/09/23 13:08:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2022-09-23 13:08:20,601] {subprocess.py:92} INFO - Setting default log level to "WARN".
[2022-09-23 13:08:20,601] {subprocess.py:92} INFO - To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[2022-09-23 13:08:21,508] {subprocess.py:92} INFO - 22/09/23 13:08:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2022-09-23 13:08:25,514] {subprocess.py:92} INFO - 
[Stage 0:>                                                          (0 + 1) / 1]

                                                                                
22/09/23 13:08:25 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2022-09-23 13:10:00,758] {subprocess.py:92} INFO - 
[Stage 1:>                                                        (0 + 12) / 14]

[Stage 1:====>                                                    (1 + 12) / 14]

[Stage 1:========>                                                (2 + 12) / 14]

[Stage 1:====================>                                     (5 + 9) / 14]

[Stage 1:=====================================>                    (9 + 5) / 14]

[Stage 1:============================================>            (11 + 3) / 14]

[Stage 1:================================================>        (12 + 2) / 14]

[Stage 1:====================================================>    (13 + 1) / 14]

                                                                                

[Stage 9:>                                                          (0 + 2) / 2]

[Stage 9:=============================>                             (1 + 1) / 2]

                                                                                

[Stage 11:>                                                       (0 + 12) / 12]

[Stage 11:====>                                                   (1 + 11) / 12]

[Stage 11:==============>                                          (3 + 9) / 12]

                                                                                

[Stage 12:>                                                       (0 + 12) / 12]

[Stage 12:====>                                                   (1 + 11) / 12]

[Stage 12:=========>                                              (2 + 10) / 12]

[Stage 12:===================>                                     (4 + 8) / 12]

[Stage 12:=======================>                                 (5 + 7) / 12]

[Stage 12:===================================================>    (11 + 1) / 12]

                                                                                
===============================================================================
[2022-09-23 13:10:00,759] {subprocess.py:92} INFO -                          Spark connection configured!
[2022-09-23 13:10:00,760] {subprocess.py:92} INFO - ===============================================================================
[2022-09-23 13:10:00,760] {subprocess.py:92} INFO - staging_immigration table loaded successfully...
[2022-09-23 13:10:00,760] {subprocess.py:92} INFO - staging_i94country loaded successfully...
[2022-09-23 13:10:00,760] {subprocess.py:92} INFO - staging_i94port loaded successfully...
[2022-09-23 13:10:00,761] {subprocess.py:92} INFO - staging_i94mode loaded successfully...
[2022-09-23 13:10:00,761] {subprocess.py:92} INFO - staging_i94address loaded successfully...
[2022-09-23 13:10:00,761] {subprocess.py:92} INFO - staging_i94visa loaded successfully...
[2022-09-23 13:10:00,761] {subprocess.py:92} INFO - staging_airport_codes table loaded successfully...
[2022-09-23 13:10:00,761] {subprocess.py:92} INFO - staging_global_temperature table loaded successfully...
[2022-09-23 13:10:00,761] {subprocess.py:92} INFO - staging_demographics table loaded successfully...
[2022-09-23 13:10:00,762] {subprocess.py:92} INFO - ===============================================================================
[2022-09-23 13:10:00,762] {subprocess.py:92} INFO -                           Staging tables are ready!
[2022-09-23 13:10:00,762] {subprocess.py:92} INFO - ===============================================================================
[2022-09-23 13:10:00,762] {subprocess.py:92} INFO - 
[2022-09-23 13:10:01,327] {subprocess.py:96} INFO - Command exited with return code 0
[2022-09-23 13:10:01,346] {taskinstance.py:1415} INFO - Marking task as SUCCESS. dag_id=us_immigration_and_demographics_dag, task_id=Load_staging_tables, execution_date=20220923T073812, start_date=20220923T073817, end_date=20220923T074001
[2022-09-23 13:10:01,397] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-09-23 13:10:01,423] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check

